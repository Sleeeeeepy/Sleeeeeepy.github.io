# 캐시 - 2
## 빠른 개요
캐시에 대한 두 번째 이야기입니다. 메모리 게층 구조에서 캐시는 CPU 레지스터와 메인 메모리 사이에 존재합니다. 캐시는 **지역성**을 바탕으로 하고 있습니다.
1. 시간적 지역성: 한 번 사용되지 않은 메모리는 잘 사용하지 않고, 이번에 사용한 메모리 지역은 다음에도 사용할 가능성이 높습니다.
2. 공간적 지역성: 상대적으로 가까운 지역의 메모리를 연속해서 사용하는 경우가 많습니다.

따라서 이 지역성을 고려해 볼 때 아래 두 루프는 서로 실행시간이 크게 다릅니다.
``` c
int arr[10000][10000] = {0};

// 방법 1
for (int i = 0; i < 10000; i++) {
    for (int j = 0; j < 10000; j++) {
        arr[i][j] = 1;
    }
}

// 방법 2
for (int i = 0; i < 10000; i++) {
    for (int j = 0; j < 10000; j++) {
        arr[j][i] = 1;
    }
}
```

## 캐시 미스 vs 캐시 히트
먼저 캐시 미스와 캐시 히트에 대해 알아봅시다. 캐시 미스는 접근하려고 하는 주소가 캐시에 매핑되지 않은 것입니다. 반대로 접근하려는 주소가 캐시에 매핑되어있다면 캐시 히트라고 합니다.

다만, 캐시 미스에도 몇 가지 구분이 있습니다. 캐시가 비어 있어 생기는 콜드 미스, 캐시의 용량이 부족해서 생기는 커패시티 미스, 캐시의 같은 공간에 다른 데이터를 쓰기 위해 발생하는 콘플릭트 미스 등이 있습니다.

그 외에도 멀티 스레드 환경에서 다른 두 코어의 로컬 캐시(L1)가 메인 메모리의 같은 부분을 올리고 있을 때, 데이터의 일관성 유지를 위해 캐시 미스가 발생하는 등 여러 요인이 있습니다. 이 경우는 아주 유명한 사례 중 하나이기도 합니다. 그래서 적지않은 프로그램들이 이를 방지하기 위해 메모리 공간을 정렬하기도 합니다. 

## 캐시의 메모리 매핑 전략
캐시에 메인 메모리를 어떻게 매핑할 것인가가 중요합니다. 어떻게 메인 메모리를 매핑하는지에 따라 성능의 차이가 크게 벌어지기 때문입니다. 일단 알고 있는 정보는 메인 메모리의 주소 정도로 한정해봅시다. 메모리 매핑에는 다음과 같은 아이디어들이 있습니다.

들어가기 앞서 몇 가지 용어들이 있습니다.
1. 캐시라인: 메인 메모리에서 한 번에 같이 캐시에 불러와지는 캐시의 일부분입니다.
2. 태그: 마치 해시 테이블의 키와 같은 역할로, 캐시라인을 구별하는 역할을 합니다.
3. 인덱스: 캐시 라인의 인덱스를 의미합니다.
4. 오프셋: 해당 캐시 라인의 오프셋을 의미합니다.

### Direct mapped
주소를 직접 매핑하는 방법입니다. 메모리 주소를 태그, 인덱스, 오프셋으로 나눕니다. 예를 들어 아래와 같은 주소가 있다고 가정합시다.
```
1111 1010 0010 1000
```
이를 아래와 같이 쪼갭니다.
```
Tag: 1111 10
Index: 1000
Offset: 1010 00
```

이제 8(1000)번 캐시라인의 태그가 62(111110)인지 검사합니다. 만약 아니라면 콘플릭트 미스를 발생시키고 캐시라인을 교체합니다. 만약 같다면 그 캐시라인의 오프셋이 40(101000)인 부분에서 데이터를 가져옵니다. 이것이 직접 사상 캐시(direct mapped cache)입니다. 교체 전략은 별도로 필요하지 않습니다. 단순히 교체만 수행하면 됩니다.

#### 캐시의 크기 알아내기
```
Tag: 1111 10
Index: 1000
Offset: 1010 00
```
이 결과를 보고 비트를 세서 캐시 라인의 크기와 캐시의 크기를 알 수 있습니다. 여기서 오프셋을 보고 캐시 라인의 크기가 $2^6$ 바이트라는 사실을 알 수 있고 인덱스를 보고 캐시는 이러한 라인을 $2^4$개 가지고 있다는 사실을 알 수 있습니다. 따라서 이 캐시의 크기는 1024 바이트입니다.

#### 태그 비트, 인덱스 비트, 오프셋의 관계
인덱스 비트의 수가 너무 작으면 캐시 미스가 지나치게 자주 발생합니다. 이를 해결하기 위해서는 인덱스 비트의 수를 늘려야합니다. 먼저 태그 비트를 줄여서 인덱스 비트를 늘려봅시다. 그러면 캐시의 크기가 커져야합니다. 하지만 캐시의 크기는 늘리면 늘릴수록 성능이 감소합니다. 반대로 캐시의 크기를 늘리지 않기 위해서 오프셋 비트를 줄이고 인덱스 비트를 늘려봅시다. 그러면 캐시 라인의 크기가 작아지게 됩니다.

### Fully associative
이제 인덱스 비트를 사용하지 않도록 합시다. 그러면 태그와 오프셋만 남으므로 캐시는 모든 주소를 동시에 매핑할 수 있습니다. 하지만 문제는 언제나 공간의 크기입니다. 공간의 크기는 한정되어있으므로 어떤 캐시를 제외할 지 결정해야 합니다. 아까 그 주소로 돌아가봅시다.
```
1111 1010 0010 1000
```
이를 아래와 같이 쪼갭니다.
```
Tag: 1111 1010 00
Offset: 1010 00
```
그러면 캐시라인의 크기는 64 바이트입니다. 이 때 만약 캐시의 용량이 2048 바이트라면 최대 32개의 캐시라인이 존재할 수 있습니다. 만약 캐시가 매핑하지 않은 주소를 요청하면 커패시티 미스가 발생하고 희생자를 선택하여 교체합니다. 만약 태그가 일치하는 캐시가 있으면 캐시 히트이고, 바로 가져옵니다. 하지만 이 방법에는 치명적인 단점이 있는데, 모든 태그비트를 검사해야 한다는 단점이 있습니다.

### Set-associative
이 방법은 두 방법을 합친 것과 같습니다. 마치 여러 개의 직접 사상 캐시를 사용하는 것처럼 작동합니다. 이 때의 갯수를 보통 way라고 부릅니다. 즉, 직접 사상 캐시는 1 way 집합 연관 캐시입니다. 4 way 집합 연관 캐시를 예로 들어봅시다.
```
1111 1010 0010 1000
```
이를 아래와 같이 쪼갭니다.
```
Tag: 1111 10
Index: 1000
Offset: 1010 00
```
여기까지는 직접 사상 캐시와 같습니다. 이제 4개의 집합에서, 각각의 집합의 인덱스가 8인 곳 중 한 곳에 태그가 62인 곳이 있는지 검사합니다. 만약 모든 집합의 해당 인덱스가 다른 태그에 할당 되어있다면 캐시 미스가 발생해서 희생자를 고릅니다. 아니면 어느 집합 중 한 곳이라도 비어있으면 콜드 미스가 발생합니다. 집합 연관 캐시는 이와 같은 방식으로 작동합니다.

#### 캐시의 크기 알아내기
이 경우 하나의 집합의 크기가 직접 사상 캐시와 같이 계산하여 1024 바이트입니다. 이러한 집합이 4개 있으므로 총 크기는 4096 바이트입니다.

## 캐시 교체 전략
직접 사상 캐시가 아닌 다른 캐시들은 모두 교체 전략이 필요합니다. 캐시 교체 전략에는 여러 가지가 있지만, 대표적으로 LRU, FIFO, second chance, random 등이 있습니다. 특히 second chance와 random이 최적 알고리즘을 훌륭하게 근사합니다.

## 캐시 쓰기 전략
쓰기 전략에는 대표적으로 두 가지가 있습니다. 하나는 Write-Back이고 다른 하나는 Wrtie-Through입니다. 전자는 캐시 메모리에만 쓰고 해당 캐시가 무효화되면 그제서야 메인 메모리에 씁니다. 다른 하나는 캐시에 쓰는 동시에 메모리에도 쓰는 방법입니다.