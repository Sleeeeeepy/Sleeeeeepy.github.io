# 캐시
## 개요
기본적으로 RAM(random access model)을 기반으로 하는 머신들, 특히 그 중에서도 폰 노이만 아키텍처를 기반으로 하는 머신들은 병목 현상을 겪는다. 대표적으로 이차 메모리에서 메인 메모리로 데이터를 로드할 때와 메인 메모리에서 CPU로 데이터를 로드할 때 병목현상이 생긴다. 우리는 메인 메모리에 로드된 수많은 데이터를 수시로 CPU에 전달해야 한다. 그러나 이는 CPU의 데이터 처리 속도에 비해 터무니 없이 낮은 속도이다. 실제 작업을 얼마 걸리지 않고 데이터를 그저 옮기는데에만 많은 시간을 사용하게 되는 것이다. 어떤 사람들은 일정 간격의 시간을 두고 메모리 사용을 관찰한 결과 메모리 사용에 다음과 같은 두 가지 특성이 있음을 알아냈다.

1. 메모리의 특정 부분을 자주 사용한다. (공간적 지역성) 
2. 한 번 잘 사용하지 않게 된 메모리는 이후에도 잘 사용하지 않는다. (시간적 지역성)

따라서 메인 메모리보다 빠른 메모리를 CPU와 메인 메모리 사이에 둘 수 있으면 비록 용량이 적더라도 유용하게 사용할 수 있다는 사실을 유추했다. 우리는 이 메모리를 캐시(cache)라고 부른다.

## 왜 캐시를 알아야하는가?
캐시는 보통 하드웨어 수준에서 조정되므로, 캐시에 대해서 알 필요가 없다고 생각할 수 있지만 그렇지 않다. 먼저 캐시에 대한 아이디어는 소프트웨어 세계에서도 많이 사용되고 있다. 예를 들어, 어떤 프로그램에서 자주 사용되는 데이터는 미리 적재할 수 있을 것이다. 그리고 캐시의 구조를 고려하여 프로그램을 작성해야 성능이 좋다. 아래 두 `for`루프가 있다.
``` c
int arr[10000][10000] = {0};

// 방법 1
for (int i = 0; i < 10000; i++) {
    for (int j = 0; j < 10000; j++) {
        arr[i][j] = 1;
    }
}

// 방법 2
for (int i = 0; i < 10000; i++) {
    for (int j = 0; j < 10000; j++) {
        arr[j][i] = 1;
    }
}
```
`time` 명령을 사용해 두 프로그램의 실행시간을 측정해보면 다음과 같다.
```
방법1: ./for_loop 0.12s user 0.03s system 96% cpu 0.148 total 
방법2: ./for_loop 0.28s user 0.05s system 99% cpu 0.331 total
```
무엇이 두 프로그램의 실행속도 차이를 만들었는가? C언어는 배열을 행 중심으로 저장한다. 따라서 두 번째 방법은 안쪽 루프가 돌 때마다 새롭게 메모리를 로드해야할 가능성이 첫 번째 방법보다 상대적으로 높다. 따라서 단순한 루프에서도 이러한 차이가 발생하게 되는 것이다.

이뿐만이 아니다. 최근의 시스템에서는 하나의 CPU에 여러 코어가 있고, 코어마다 각각의 캐시를 갖는다. 데이터의 일관성을 유지하기 위해서 다른 코어가 같은 영역의 메모리를 수정한다면 메인 메모리에 그 내용을 반영하고 새롭게 캐시에 해당 데이터 영역을 다시 로드한다. 이러한 시스템에서 캐시를 고려하지 않는다면 데이터의 일관성을 유지하기 위해 메인 메모리 접근이 과도해지고, 결국에는 병렬 처리를 하지 않는 것이 훨씬 빠를만큼 느리게 작동한다.

## 메모리 계층구조
메모리는 계층 구조를 이룬다. 이차 메모리에서 메인 메모리로 데이터가 이동하고, 메인 메모리에서 캐시로 데이터가 이동하고, 캐시에서 레지스터로 데이터가 이동한다. 최근에는 이러한 단계를 생략하는 방법도 있지만, 여전히 대부분의 데이터는 이러한 경로를 따른다. CPU에서 하나의 연산을 수행하는데 1 사이클이 걸린다고 가정하고, 데이터를 CPU에 불러올 때 까지 걸리는 시간은 대략적으로 다음과 같다. 시스템마다 다를 수 있지만 경향성은 다음과 같다.

1. 레지스터: 1 사이클 미만
2. L1 캐시: 1~5 사이클
3. L2 캐시: 5~20 사이클
4. L3 캐시: 20~80 사이클
5. 메인 메모리: 200~300 사이클
6. 이차 저장 장치: 수 밀리초~
7. 원격 저장 장치: 수십 밀리초~
